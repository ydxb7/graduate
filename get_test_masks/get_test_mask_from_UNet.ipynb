{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = (20, 20)\n",
    "# plt.rcParams['image.interpolation'] = 'bilinear'\n",
    "\n",
    "import sys\n",
    "sys.path.append('../train/')\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import collections\n",
    "import numbers\n",
    "import random\n",
    "import math\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from networks.UNet_check import UNet_check\n",
    "import tool\n",
    "from tqdm import tqdm\n",
    "\n",
    "flip_index = ['16', '15', '14', '13', '12', '11', '10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 2 \n",
    "BATCH_SIZE = 8\n",
    "W, H = 1918, 1280\n",
    "STRIDE = 388\n",
    "IMAGE_SIZE = 572\n",
    "test_mask_path = '../../data/test_masks/UNet/'\n",
    "weight_path = '../_weights/UNet_check-fold0-0.00549.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename, model):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = UNet_check()\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "load_model(weight_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '../../data/images/test/'\n",
    "\n",
    "if not os.path.exists(test_mask_path):\n",
    "    os.makedirs(test_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = os.listdir(test_path)\n",
    "test_names = sorted(test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords_full = np.zeros((BATCH_SIZE, 2, H, W), dtype='float32')\n",
    "# xx,yy = np.meshgrid(np.linspace(-0.5,0.5,W), np.linspace(-0.5,0.5,H))\n",
    "# coord = np.concatenate([xx[np.newaxis,...], yy[np.newaxis,...]],0).astype('float32')\n",
    "# for i in range(BATCH_SIZE):\n",
    "#     coords_full[i] = coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = 572 - 388"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_size = BATCH_SIZE\n",
    "    normalize_mean = [.485, .456, .406]\n",
    "    normalize_std = [.229, .224, .225]\n",
    "\n",
    "    test_names = sorted(os.listdir(test_path))\n",
    "    for image_pack in tqdm(range(len(test_names) // batch_size)):\n",
    "        images = np.zeros((batch_size, 3, H + board, W + board), dtype='float32')\n",
    "        test_masks = np.zeros((batch_size, 2, H, W), dtype='float32')\n",
    "        ifflip = [False] * batch_size\n",
    "        image_batch_names = test_names[image_pack * batch_size: image_pack * batch_size + batch_size]\n",
    "        mask_names = [input_name.split('.')[0] + '.png' for input_name in image_batch_names]\n",
    "        \n",
    "        for idx, image_name in enumerate(image_batch_names):\n",
    "            image = Image.open(os.path.join(test_path, image_name))\n",
    "            angle = image_name.split('.')[0].split('_')[-1]\n",
    "            if angle in flip_index:\n",
    "                ifflip[idx] = True\n",
    "                image = ImageOps.mirror(image)\n",
    "\n",
    "            image = np.array(image).astype('float') / 255\n",
    "            image = image.transpose(2, 0, 1)\n",
    "            img = np.zeros((3, H + board, W + board), dtype='float32')\n",
    "            img[:, board // 2:-board // 2, board // 2:-board // 2] = image\n",
    "            image = img\n",
    "\n",
    "            for i in range(3):\n",
    "                image[i] = (image[i] - normalize_mean[i]) / normalize_std[i]\n",
    "\n",
    "            images[idx] = image\n",
    "            \n",
    "            \n",
    "#             images[idx] = image\n",
    "    \n",
    "\n",
    "        for h_idx in range(int(math.ceil((H + board - STRIDE) / STRIDE))):\n",
    "            h_start = h_idx * STRIDE\n",
    "            h_end = h_start + 572\n",
    "            \n",
    "            mask_h_start = h_idx * STRIDE\n",
    "            mask_h_end = mask_h_start + 388\n",
    "            \n",
    "            if h_end > H + board:\n",
    "                h_end = H + board\n",
    "                h_start = h_end - 572\n",
    "                \n",
    "                mask_h_end = H\n",
    "                mask_h_start = mask_h_end - 388\n",
    "                \n",
    "            for w_idx in range(int(math.ceil((W + board - STRIDE) / STRIDE))):\n",
    "                w_start = w_idx * STRIDE\n",
    "                w_end = w_start + 572\n",
    "                \n",
    "                mask_w_start = w_idx * STRIDE\n",
    "                mask_w_end = mask_w_start + 388\n",
    "                \n",
    "                if w_end > W + board:\n",
    "                    w_end = W + board\n",
    "                    w_start = w_end - 572\n",
    "                    \n",
    "                    mask_w_end = W\n",
    "                    mask_w_start = mask_w_end - 388\n",
    "\n",
    "                input_batchs = images[:, :, h_start:h_end, w_start:w_end]\n",
    "                input_tensor = torch.from_numpy(input_batchs).cuda()\n",
    "                inputs = Variable(input_tensor)\n",
    "                \n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                ouputs = outputs.cpu().data.numpy()\n",
    "\n",
    "                test_masks[:, :, mask_h_start:mask_h_end, mask_w_start:mask_w_end] += ouputs\n",
    "        \n",
    "    \n",
    "        test_masks = np.argmax(test_masks, axis=1).astype('uint8')\n",
    "        for idx in range(batch_size):\n",
    "            output_PIL = Image.fromarray(test_masks[idx].astype('uint8')*255).convert('1')\n",
    "            if ifflip[idx]:\n",
    "                output_PIL = ImageOps.mirror(output_PIL)\n",
    "            mask_name = mask_names[idx]\n",
    "            output_PIL.save(test_mask_path + mask_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
